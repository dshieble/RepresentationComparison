{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be difficult to quantify the impact of changing a hyperparameter on an embedding model. In this notebook we use matrix factorization to train a couple of movie embedding models based on the MovieLens dataset, and then use embedding comparison to see how changing the value of hyperparameters affects the learned embedding spaces.\n",
    "\n",
    "We also show how certain hyperparameter settings for WALS create embedding spaces very similar to those that we would learn with SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from experiment_helpers import (\n",
    "    get_embeddings_from_ratings_df,\n",
    "    compare_embedding_maps\n",
    ")\n",
    "from embeddingcomp.comparison import CCAComparison, UnitMatchComparison, NeighborsComparison\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "logging.getLogger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data (MovieLens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../../data\"\n",
    "\n",
    "# dataset = \"ml-1m\"\n",
    "dataset = \"ml-20m\"\n",
    "\n",
    "clear_command = \"rm -rf {}/{}\".format(data_path, dataset)\n",
    "os.system(clear_command)\n",
    "\n",
    "urlretrieve(\"http://files.grouplens.org/datasets/movielens/{}.zip\".format(dataset),\n",
    "            \"{}/{}.zip\".format(data_path, dataset))\n",
    "\n",
    "unzip_command = \"unzip {}/{}.zip  -d {}\".format(data_path, dataset, data_path)\n",
    "subprocess.check_output(unzip_command, shell=True)\n",
    "\n",
    "headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "if dataset == \"ml-1m\":  \n",
    "    ratings_df  = pd.read_csv(\"{}/{}/ratings.dat\".format(data_path, dataset),\n",
    "                  delimiter=\"::\", header=None, names=headers)\n",
    "    \n",
    "    # Load the movie titles\n",
    "    movie_df = pd.read_csv(\"{}/{}/movies.dat\".format(data_path, dataset), delimiter=\"::\", header=None)\n",
    "    id_to_title = dict(zip(movie_df[0].values, zip(movie_df[1].values, movie_df[2].values)))\n",
    "elif dataset == \"ml-20m\":\n",
    "    ratings_df  = pd.read_csv(\"{}/{}/ratings.csv\".format(data_path, dataset),\n",
    "                  delimiter=\",\", header=0, names=headers)\n",
    "\n",
    "    # Load the movie titles\n",
    "    movie_df = pd.read_csv(\"{}/{}/movies.csv\".format(data_path, dataset))\n",
    "    id_to_title = dict(zip(movie_df['movieId'].values, zip(movie_df['title'].values, movie_df['genres'].values)))\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "ratings_df['item_id'] = [id_to_title[item_id] for item_id in ratings_df['item_id'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train example WALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ('Accattone (1961)', 'Drama') \n",
      "Results: \n",
      "('Young and the Damned, The (Olvidados, Los) (1950)', 'Crime|Drama')\n",
      "('Investigation of a Citizen Above Suspicion (Indagine su un cittadino al di sopra di ogni sospetto) (1970)', 'Crime|Drama|Thriller')\n",
      "('Cul-de-sac (1966)', 'Comedy|Crime|Drama|Thriller')\n",
      " ----- \n",
      "\n",
      "Query: ('They Live (1988)', 'Action|Sci-Fi|Thriller') \n",
      "Results: \n",
      "('Scanners (1981)', 'Horror|Sci-Fi|Thriller')\n",
      "('Shogun Assassin (1980)', 'Action|Adventure')\n",
      "('Big Boss, The (Fists of Fury) (Tang shan da xiong) (1971)', 'Action|Thriller')\n",
      " ----- \n",
      "\n",
      "Query: ('Dragon Ball Z: Broly Second Coming (Doragon bôru Z 10: Kiken na futari! Sûpâ senshi wa nemurenai) (1994)', 'Action|Adventure|Animation') \n",
      "Results: \n",
      "('Ironclad (2011)', 'Action|Adventure')\n",
      "('Secuestrados (Kidnapped) (2010)', 'Horror|Thriller')\n",
      "('Sharknado (2013)', 'Sci-Fi')\n",
      " ----- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from embeddingcomp.neighbors import get_neighbors_table\n",
    "\n",
    "# Train the matrix factorization model\n",
    "movie_to_embedding = get_embeddings_from_ratings_df(\n",
    "    ratings_df, algorithm=\"wals\", latent_factors=10, unobs_weight=0.01)[1]\n",
    "\n",
    "# Look at the nearest neighbors by movie\n",
    "movie_names = list(movie_to_embedding.keys())\n",
    "movie_embeddings = np.vstack(movie_to_embedding.values())\n",
    "table =  get_neighbors_table(movie_embeddings, \"brute\")\n",
    "for index in np.random.permutation(range(len(movie_to_embedding)))[:3]:\n",
    "    neighbor_indices = table.get_neighbors(index, 3)\n",
    "    print(\"Query: {} \\nResults: \\n{}\\n ----- \\n\".format(\n",
    "        movie_names[index],\n",
    "        \"\\n\".join([str(movie_names[neighbor_index]) for neighbor_index in neighbor_indices])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the effect of a hyperparameters on the learned WALS embedding space\n",
    "One of the important hyperparameters of a WALS model is the amount of weight to assign the unobserved elements. In this experiment we look at how increasing the unobserved weights that we use to train the WALS models yields distinct movie embedding spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-551fb0f4060f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbaseline_movie_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings_from_ratings_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m retrained_movie_embeddings = [get_embeddings_from_ratings_df(ratings_df, alg, factors, uweight)[1]\n\u001b[0;32m----> 7\u001b[0;31m                               for uweight in uweights]\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompare_embedding_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_movie_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretrained_movie_embeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-551fb0f4060f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbaseline_movie_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings_from_ratings_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m retrained_movie_embeddings = [get_embeddings_from_ratings_df(ratings_df, alg, factors, uweight)[1]\n\u001b[0;32m----> 7\u001b[0;31m                               for uweight in uweights]\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompare_embedding_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_movie_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretrained_movie_embeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/embeddingcomp/experiments/Movie_Embedding_Experiment/experiment_helpers.py\u001b[0m in \u001b[0;36mget_embeddings_from_ratings_df\u001b[0;34m(ratings_df, algorithm, latent_factors, unobs_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0moutput_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_factorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_factors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munobs_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"time elapsed {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/embeddingcomp/experiments/Movie_Embedding_Experiment/experiment_helpers.py\u001b[0m in \u001b[0;36mrun_factorization\u001b[0;34m(sparse_matrix, algorithm, latent_factors, unobs_weight)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"wals\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     output_row, output_col = train_model_on_sparse_matrix(\n\u001b[0;32m---> 27\u001b[0;31m       sparse_matrix, latent_factors=latent_factors, unobs_weight=unobs_weight)\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"svd\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfptype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/embeddingcomp/experiments/Movie_Embedding_Experiment/wals.py\u001b[0m in \u001b[0;36mtrain_model_on_sparse_matrix\u001b[0;34m(sparse_matrix, latent_factors, unobs_weight, num_iters, regularization, weights, wt_type, feature_wt_factor, feature_wt_exp)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                                                 \u001b[0mwt_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                                 \u001b[0mfeature_wt_exp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                                                 feature_wt_factor)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;31m# factorize matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/embeddingcomp/experiments/Movie_Embedding_Experiment/wals.py\u001b[0m in \u001b[0;36mwals_model\u001b[0;34m(data, dim, reg, unobs, weights, wt_type, feature_wt_exp, obs_wt)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mfeature_wt_exp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mrow_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mcol_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_wts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_wt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_wt_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0mrow_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/embeddingcomp/experiments/Movie_Embedding_Experiment/wals.py\u001b[0m in \u001b[0;36mmake_wts\u001b[0;34m(data, wt_type, obs_wt, feature_wt_exp, axis)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \"\"\"\n\u001b[1;32m    129\u001b[0m   \u001b[0;31m# recipricol of sum of number of items across rows (if axis is 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;31m# filter any invalid entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepfakes/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__gt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__gt__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__le__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepfakes/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepfakes/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deepfakes/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1059\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alg = \"wals\"\n",
    "factors = 10\n",
    "uweights = [0.0, 0.01, 0.1, 0.5, 1.0, 2.0]\n",
    "\n",
    "baseline_movie_embedding = get_embeddings_from_ratings_df(ratings_df, alg, factors, 0.0)[1]\n",
    "retrained_movie_embeddings = [get_embeddings_from_ratings_df(ratings_df, alg, factors, uweight)[1]\n",
    "                              for uweight in uweights]\n",
    "similarities = [compare_embedding_maps(baseline_movie_embedding, ret) for ret in retrained_movie_embeddings]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Neighbor Method\")\n",
    "plt.xlabel(\"Unobserved Element Weight\")\n",
    "plt.ylabel(\"Similarity to Unobserved Weight = 0\")\n",
    "plt.plot(uweights, [s[\"neighbor\"] for s in similarities])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CCA Method\")\n",
    "plt.xlabel(\"Unobserved Element Weight\")\n",
    "plt.ylabel(\"Similarity to Unobserved Weight = 0\")\n",
    "plt.plot(uweights, [s[\"cca\"] for s in similarities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train an SVD model compares to these learned WALS models. Since the loss that SVD minimizes does't bias towards all of the elements in the matrix we see that the SVD embeddings are most similar to the WALS embeddings trained with larger unobserved weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd_movie_embedding = get_embeddings_from_ratings_df(ratings_df, \"svd\", factors, None)[1]\n",
    "svd_similarities = [compare_embedding_maps(svd_movie_embedding, ret) for ret in retrained_movie_embeddings]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Neighbor Method\")\n",
    "plt.xlabel(\"Unobserved Element Weight\")\n",
    "plt.ylabel(\"Similarity to SVD Embeddings\")\n",
    "plt.plot(uweights, [s[\"neighbor\"] for s in svd_similarities])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"CCA Method\")\n",
    "plt.xlabel(\"Unobserved Element Weight\")\n",
    "plt.ylabel(\"Similarity to SVD Embeddings\")\n",
    "plt.plot(uweights, [s[\"cca\"] for s in svd_similarities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfakes",
   "language": "python",
   "name": "deepfakes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
